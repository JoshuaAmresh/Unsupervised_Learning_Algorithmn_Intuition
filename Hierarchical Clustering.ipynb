{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'Hierarchical.PNG'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In hierarchical clustering, the model begins by treating each individual point as different clusters. The it proceeds to find the point closest to the cluster and groups it together as one cluster. Example, red cluster with p1 and p2 above. Likewise in each initial cluster it finds the closest points to form a cluster. Then, the closest clusters themselves are grouped together as a cluster. Example violet and blue clustered together as green above. This goes on till all the points fall under a single cluster. While clusters are being formed, dendogram is also drawn with the distance metrics of the cluster. To determine the optimal number of clusters using hierarchical clustering, the hack is to find the longest vertical line where no horizontal line is cutting through (as seen above). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
